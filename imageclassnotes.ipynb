{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup dependencies \n",
    "- This step involves importing things like tensorflow, matplotlib and opencv-python \n",
    "\n",
    "#### OS:\n",
    "- Importing os helps with returning file structures that are applicable to any operating system\n",
    "- The os.listdir() functions will list the contents of the input directory\n",
    "- The function os.path.join() will join concatentate two path components so that the location can be interpreted. eg. os.path.join(data_dir, '1 x 2 bricks [1 pin hole]') = 'data\\\\1 x 2 bricks [1 pin hole]'\n",
    "\n",
    "#### GPU config:\n",
    "This line helps prevent tensorflow from using up all the GPU memory: \"tf.config.experimental.set_memory_growth('GPU', True)\".\n",
    "By limiting this it will help prevent out of memory errors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Cleaning the image data set\n",
    "\n",
    "#### Useful functions:\n",
    "- The imghdr.what() function will return the file type of the input\n",
    "- os.remove() will remove the file specified by the file path passed into the function from the directory of interest \n",
    "\n",
    "#### Extra:\n",
    "I used some photos I took from my phone camera and an easy way i found to convert from heic to jpg was iloveimg.com\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Preprocessing steps\n",
    "- Scale images ie have the color values be between 1 and 0 instead of 255 and 0\n",
    "- We want to divide the available data into test, train and validations sets\n",
    "- When using the skip and take functions, we want to first take the training data out, then validation data, then test data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Deep learning model \n",
    "- Sequential is an API used for simpler models with single data input and single data output \n",
    "- Conv2D - a 2D convolutional layer \n",
    "- MaxPooling2D - condenses images (eg simplifies a region to its max value)\n",
    "- Dense - a fully connected layer \n",
    "- Flatten - a layer allowing us to reduce the format into something that Dense can handle, ie transform multidimensional input into single dimension output\n",
    "- Dropout - regularization \n",
    "\n",
    "#### Adding layers:\n",
    "- model.add(Conv2D(16, (3,3), 1), 1, activation = 'relu', input_shape=(256, 256, 3))\n",
    "This convolutional layer has 16 filter, each is 3 by 3 pixels with a stride of 1 (the number of pixels it moves each time). \n",
    "The activation parameter passes the output of this layer and fits it to a function that convert -ve vals to 0 and any +ve vals remain the same\n",
    "\n",
    "- model.add(MaxPooling2D()) \n",
    "This layer takes the max value after relu activation and return it. By default finds max data over a 2 by 2 region (essentially halves data)\n",
    "\n",
    "- model.add(Flatten())\n",
    "When we apply convulational layers, filters will be the channel value (which not necessary for the following dense layers)\n",
    "\n",
    "- model.add(Dense(256), activation = 'relu')\n",
    "Adding a fully connected layer with 256 neurons \n",
    "\n",
    "- model.add(Dense(1), activation = 'sigmoid')\n",
    "Final layer is a single neuron, produces an output of between 0 and 1 which will map to the input classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model notes and reflection:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This model works if the image provided has the subject facing forwards so that most of their face is visible\n",
    "- In future, I wish to generalize this pipeline to recognize lego bricks and convert it to a non binary classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imageclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
